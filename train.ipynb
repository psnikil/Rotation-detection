{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdcc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraraies to import \n",
    "\n",
    "\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm \n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import imutils\n",
    "import math\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import h5py\n",
    "import tensorflow\n",
    "#from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model,load_model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.layers import Conv2D, MaxPool2D,  Dropout,Flatten, Input, concatenate, Dense\n",
    "from keras.datasets import mnist,cifar100\n",
    "from keras.preprocessing.image import Iterator\n",
    "import keras.backend as K\n",
    "import scipy\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntions for data aug and collection\n",
    "\n",
    "def create_data(X):\n",
    "    data_dict = {}\n",
    "    shp =X.shape\n",
    "    print(shp)\n",
    "    rot_img = []\n",
    "    y = []\n",
    "    for i in X:\n",
    "        img  = i\n",
    "        rotation_angle = np.random.randint(36)\n",
    "        rotated_image =  generate_rotated_image(img, angle=-(rotation_angle*10))\n",
    "        rotated_image = cv2.resize(rotated_image, (96,96))\n",
    "        #print('rot img',rotated_image.shape)\n",
    "        #img_1 = img/255\n",
    "        #rotated_image_1 = rotated_image/255\n",
    "        #data_dict['img'].append(img_1)\n",
    "        #data_dict['rot_img'].append(rotated_image_1)\n",
    "        rot_img.append(np.array(rotated_image))\n",
    "        #y.append([np.sin(rotation_angle),np.cos(rotation_angle)])\n",
    "        y.append(rotation_angle)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print('rot donee')\n",
    "    rot_img = np.array(rot_img)\n",
    "    X1 = X/255\n",
    "    rot_img1 = rot_img/255\n",
    "    data_dict['img'] = X1 \n",
    "    data_dict['rot_img'] = rot_img1\n",
    "    batch_y = to_categorical(y, 36)\n",
    "    y1 =np.array(y) \n",
    "    y = np.array((180-np.array(y))/180)\n",
    "    return data_dict,batch_y\n",
    "def create_data2(X,x1,y):\n",
    "    data_dict = {}\n",
    "    x = X\n",
    "    rot_img = x1\n",
    "    y = y//10\n",
    "    \n",
    "#     shp =X.shape\n",
    "#     print(shp)\n",
    "#     rot_img = []\n",
    "#     y = []\n",
    "#     for i in X:\n",
    "#         img  = i\n",
    "#         rotation_angle = np.random.randint(360)\n",
    "#         rotated_image =  generate_rotated_image(img, angle=-rotation_angle,size=img.shape)\n",
    "#         #print('rot img',rotated_image.shape)\n",
    "#         #img_1 = img/255\n",
    "#         #rotated_image_1 = rotated_image/255\n",
    "#         #data_dict['img'].append(img_1)\n",
    "#         #data_dict['rot_img'].append(rotated_image_1)\n",
    "#         rot_img.append(rotated_image)\n",
    "#         y.append(rotation_angle)\n",
    "    \n",
    "    \n",
    "    print('rot donee')\n",
    "    rot_img = np.array(rot_img)\n",
    "    X1 = x/255\n",
    "    #print\n",
    "    rot_img1 = rot_img/255\n",
    "    data_dict['img'] = X1 \n",
    "    data_dict['rot_img'] = rot_img1\n",
    "    batch_y = to_categorical(y, 36) \n",
    "    #y =[np.sin(rotation_angle),np.cos(rotation_angle)] \n",
    "    return data_dict,batch_y\n",
    "\n",
    "def angle_difference(x, y):\n",
    "    \"\"\"\n",
    "    Calculate minimum difference between two angles.\n",
    "    \"\"\"\n",
    "    return 180 - abs(abs(x - y) - 180)\n",
    "    #return abs(x - y)\n",
    "\n",
    "\n",
    "def angle_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the mean diference between the true angles\n",
    "    and the predicted angles. Each angle is represented\n",
    "    as a binary vector.\n",
    "    \"\"\"\n",
    "    diff = angle_difference(K.argmax(y_true), K.argmax(y_pred))\n",
    "    return K.mean(K.cast(K.abs(diff), K.floatx()))\n",
    "\n",
    "def binarize_images(x):\n",
    "    \"\"\"\n",
    "    Convert images to range 0-1 and binarize them by making\n",
    "    0 the values below 0.1 and 1 the values above 0.1.\n",
    "    \"\"\"\n",
    "    x /= 255\n",
    "    x[x >= 0.1] = 1\n",
    "    x[x < 0.1] = 0\n",
    "    return x\n",
    "\n",
    "def angle_error_regression(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the mean diference between the true angles\n",
    "    and the predicted angles. Each angle is represented\n",
    "    as a float number between 0 and 1.\n",
    "    \"\"\"\n",
    "    return K.mean(angle_difference(y_true * 360, y_pred * 360))\n",
    "\n",
    "def rotate(image, angle):\n",
    "    \"\"\"\n",
    "    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n",
    "    (in degrees). The returned image will be large enough to hold the entire\n",
    "    new image, with a black background\n",
    "    Source: http://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders\n",
    "    \"\"\"\n",
    "    # Get the image size\n",
    "    # No that's not an error - NumPy stores image matricies backwards\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    image_center = tuple(np.array(image_size) / 2)\n",
    "\n",
    "    # Convert the OpenCV 3x2 rotation matrix to 3x3\n",
    "    rot_mat = np.vstack(\n",
    "        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n",
    "    )\n",
    "\n",
    "    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n",
    "\n",
    "    # Shorthand for below calcs\n",
    "    image_w2 = image_size[0] * 0.5\n",
    "    image_h2 = image_size[1] * 0.5\n",
    "\n",
    "    # Obtain the rotated coordinates of the image corners\n",
    "    rotated_coords = [\n",
    "        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n",
    "    ]\n",
    "\n",
    "    # Find the size of the new image\n",
    "    x_coords = [pt[0] for pt in rotated_coords]\n",
    "    x_pos = [x for x in x_coords if x > 0]\n",
    "    x_neg = [x for x in x_coords if x < 0]\n",
    "\n",
    "    y_coords = [pt[1] for pt in rotated_coords]\n",
    "    y_pos = [y for y in y_coords if y > 0]\n",
    "    y_neg = [y for y in y_coords if y < 0]\n",
    "\n",
    "    right_bound = max(x_pos)\n",
    "    left_bound = min(x_neg)\n",
    "    top_bound = max(y_pos)\n",
    "    bot_bound = min(y_neg)\n",
    "\n",
    "    new_w = int(abs(right_bound - left_bound))\n",
    "    new_h = int(abs(top_bound - bot_bound))\n",
    "\n",
    "    # We require a translation matrix to keep the image centred\n",
    "    trans_mat = np.matrix([\n",
    "        [1, 0, int(new_w * 0.5 - image_w2)],\n",
    "        [0, 1, int(new_h * 0.5 - image_h2)],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Compute the tranform for the combined rotation and translation\n",
    "    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n",
    "\n",
    "    # Apply the transform\n",
    "    result = cv2.warpAffine(\n",
    "        image,\n",
    "        affine_mat,\n",
    "        (new_w, new_h),\n",
    "        flags=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def largest_rotated_rect(w, h, angle):\n",
    "    \"\"\"\n",
    "    Given a rectangle of size wxh that has been rotated by 'angle' (in\n",
    "    radians), computes the width and height of the largest possible\n",
    "    axis-aligned rectangle within the rotated rectangle.\n",
    "    Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n",
    "    Converted to Python by Aaron Snoswell\n",
    "    Source: http://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders\n",
    "    \"\"\"\n",
    "\n",
    "    quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n",
    "    sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n",
    "    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n",
    "\n",
    "    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n",
    "    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n",
    "\n",
    "    gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n",
    "\n",
    "    delta = math.pi - alpha - gamma\n",
    "\n",
    "    length = h if (w < h) else w\n",
    "\n",
    "    d = length * math.cos(alpha)\n",
    "    a = d * math.sin(alpha) / math.sin(delta)\n",
    "\n",
    "    y = a * math.cos(gamma)\n",
    "    x = y * math.tan(gamma)\n",
    "\n",
    "    return (\n",
    "        bb_w - 2 * x,\n",
    "        bb_h - 2 * y\n",
    "    )\n",
    "\n",
    "\n",
    "def crop_around_center(image, width, height):\n",
    "    \"\"\"\n",
    "    Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n",
    "    around it's centre point\n",
    "    Source: http://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders\n",
    "    \"\"\"\n",
    "\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n",
    "\n",
    "    if(width > image_size[0]):\n",
    "        width = image_size[0]\n",
    "\n",
    "    if(height > image_size[1]):\n",
    "        height = image_size[1]\n",
    "\n",
    "    x1 = int(image_center[0] - width * 0.5)\n",
    "    x2 = int(image_center[0] + width * 0.5)\n",
    "    y1 = int(image_center[1] - height * 0.5)\n",
    "    y2 = int(image_center[1] + height * 0.5)\n",
    "\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "def crop_largest_rectangle(image, angle, height, width):\n",
    "    \"\"\"\n",
    "    Crop around the center the largest possible rectangle\n",
    "    found with largest_rotated_rect.\n",
    "    \"\"\"\n",
    "    return crop_around_center(\n",
    "        image,\n",
    "        *largest_rotated_rect(\n",
    "            width,\n",
    "            height,\n",
    "            math.radians(angle)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_rotated_image(image, angle, size=None, crop_center=True,\n",
    "                           crop_largest_rect=True):\n",
    "    \"\"\"\n",
    "    Generate a valid rotated image for the RotNetDataGenerator. If the\n",
    "    image is rectangular, the crop_center option should be used to make\n",
    "    it square. To crop out the black borders after rotation, use the\n",
    "    crop_largest_rect option. To resize the final image, use the size\n",
    "    option.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    if crop_center:\n",
    "        if width < height:\n",
    "            height = width\n",
    "        else:\n",
    "            width = height\n",
    "\n",
    "    image = rotate(image, angle)\n",
    "\n",
    "    if crop_largest_rect:\n",
    "        image = crop_largest_rectangle(image, angle, height, width)\n",
    "\n",
    "    if size:\n",
    "        image = cv2.resize(image, size)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and combing data\n",
    "\n",
    "\n",
    "ata = np.load('coco_train2.npy')\n",
    "print(ata.shape)\n",
    "data = np.load('coco_train_rot2.npy')\n",
    "y = np.load('coco_train_y2.npy')\n",
    "print(data.shape)\n",
    "print(y.shape)\n",
    "#print(ata[2].shape)\n",
    "train = ata[:-65000]\n",
    "train_rot = data[:-65000]\n",
    "train_y = y[:-65000]\n",
    "\n",
    "test = ata[-10000:]\n",
    "test_rot = data[-10000:]\n",
    "test_y = y[-10000:]\n",
    "\n",
    "\n",
    "\n",
    "print('1',train.shape)\n",
    "print('2',train_rot.shape)\n",
    "print('3',train_y.shape)\n",
    "print('4',test.shape)\n",
    "print('5',test_rot.shape)\n",
    "print('6',test_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dx = ndimage.sobel(ata[764], 0)  # horizontal derivative\n",
    "dy = ndimage.sobel(ata[764], 1)  # vertical derivative\n",
    "mag = np.hypot(dx, dy)  # magnitude\n",
    "mag *= 255.0 / np.max(mag)  # normalize (Q&D)\n",
    "plt.imshow(mag)\n",
    "plt.show()\n",
    "\n",
    "print(y[764])\n",
    "plt.imshow(ata[764])\n",
    "# print(X_train[5].shape)\n",
    "# print(x.shape)\n",
    "# plt.imshow(X_train[5])\n",
    "plt.show()\n",
    "plt.imshow(data[764])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model in use \n",
    "\n",
    "\n",
    "model_name = 'rotnet_11_1'\n",
    "\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "nb_train_samples, img_rows, img_cols = train.shape\n",
    "\n",
    "input_shape = train.shape[1:]\n",
    "nb_test_samples = test.shape[0]\n",
    "\n",
    "print('Input shape:', input_shape)\n",
    "print(nb_train_samples, 'train samples')\n",
    "print(nb_test_samples, 'test samples')\n",
    "\n",
    "\n",
    "inp1 = Input((96,96,1), name='img')\n",
    "# xx = Conv2D(128, kernel_size, activation='relu')(inp1)\n",
    "# xx = MaxPool2D(pool_size=(2, 2))(xx)\n",
    "\n",
    "\n",
    "\n",
    "inp2 = Input((96,96,1),name='rot_img')\n",
    "# xx2 = Conv2D(128, kernel_size, activation='relu')(inp2)\n",
    "# xx2 = MaxPool2D(pool_size=(2, 2))(xx2)\n",
    "\n",
    "deepVO = concatenate([inp1, inp2],axis=-1)\n",
    "deepVO = Conv2D(64, kernel_size, activation='relu')(deepVO)\n",
    "deepVO = Conv2D(64, kernel_size, activation='relu')(deepVO)\n",
    "deepVO = MaxPool2D(pool_size=(2, 2))(deepVO)\n",
    "deepVO = Dropout(0.25)(deepVO)\n",
    "deepVO = Flatten()(deepVO)\n",
    "deepVO = Dense(128, activation='relu')(deepVO)\n",
    "deepVO = Dropout(0.25)(deepVO)\n",
    "output =  Dense(36,activation='softmax')(deepVO)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fitting the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(loss= tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
    "#               optimizer='adam')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[angle_error,tensorflow.keras.metrics.CategoricalAccuracy()])#tensorflow.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# training parameters\n",
    "batch_size = 2\n",
    "nb_epoch = 50\n",
    "\n",
    "output_folder = 'models'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# callbacks\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join(output_folder, model_name + '.hdf5'),\n",
    "    save_best_only=True\n",
    ")\n",
    "#early_stopping = EarlyStopping(patience=2)\n",
    "tensorboard = TensorBoard()\n",
    "\n",
    "x,y=create_data2(train,train_rot,train_y)\n",
    "\n",
    "# training loop\n",
    "model.fit(\n",
    "    x=[x['img'],x['rot_img']],\n",
    "    y=y,\n",
    "    steps_per_epoch=nb_train_samples / batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    validation_data=create_data2(test,test_rot,test_y),\n",
    "    validation_steps=nb_test_samples / batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpointer, tensorboard]\n",
    ")\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
